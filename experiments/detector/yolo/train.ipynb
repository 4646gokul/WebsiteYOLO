{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset import read_wider_meta\n",
    "\n",
    "from utils import letterbox_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative annotations found @ ./data/WIDER_train/images/54--Rescue/54_Rescue_rescuepeople_54_29.jpg\n",
      "Annotation: [1050, 142, -26, 50, 2, 0, 0, 0, 1, 0]\n",
      "\n",
      "Negative annotations found @ ./data/WIDER_train/images/7--Cheering/7_Cheering_Cheering_7_17.jpg\n",
      "Annotation: [0, 5, -11, 5, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Negative annotations found @ ./data/WIDER_val/images/39--Ice_Skating/39_Ice_Skating_iceskiing_39_583.jpg\n",
      "Annotation: [1026, 474, -2, 23, 2, 0, 0, 0, 2, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_root = './data/'\n",
    "\n",
    "# # calculate\n",
    "# train_meta = read_wider_meta(data_root, phase='train')\n",
    "# val_meta = read_wider_meta(data_root, phase='val')\n",
    "# test_meta = read_wider_meta(data_root, phase='test')\n",
    "\n",
    "# with open('./data/train.json', 'w') as fwrite:\n",
    "#     json.dump(train_meta, fwrite)\n",
    "    \n",
    "# with open('./data/val.json', 'w') as fwrite:\n",
    "#     json.dump(val_meta, fwrite)\n",
    "\n",
    "# with open('./data/test.json', 'w') as fwrite:\n",
    "#     json.dump(test_meta, fwrite)\n",
    "\n",
    "# Negative annotations found @ ./data/WIDER_train/images/54--Rescue/54_Rescue_rescuepeople_54_29.jpg\n",
    "# Annotation: [1050, 142, -26, 50, 2, 0, 0, 0, 1, 0]\n",
    "# Negative annotations found @ ./data/WIDER_train/images/7--Cheering/7_Cheering_Cheering_7_17.jpg\n",
    "# Annotation: [0, 5, -11, 5, 0, 0, 0, 0, 0, 0]\n",
    "# Negative annotations found @ ./data/WIDER_val/images/39--Ice_Skating/39_Ice_Skating_iceskiing_39_583.jpg\n",
    "# Annotation: [1026, 474, -2, 23, 2, 0, 0, 0, 2, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.json', 'r') as fread:\n",
    "    train_meta = json.load(fread)\n",
    "    \n",
    "with open('./data/val.json', 'r') as fread:\n",
    "    val_meta = json.load(fread)\n",
    "    \n",
    "with open('./data/test.json', 'r') as fread:\n",
    "    test_meta = json.load(fread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import Compose\n",
    "# from dataset import WIDERdataset, ToTensor\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# val_transforms = Compose([\n",
    "#     ToTensor()\n",
    "# ])\n",
    "\n",
    "# val_dataset = WIDERdataset('./data/val.json', 'val', 608, val_transforms)\n",
    "# img, targets = val_dataset.__getitem__(1885, show_examples=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.inf < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sudivisions of a batch aren't used in contrast to the original cfg\n",
      "we also can remove bias due to bn\n",
      "make_layers returns net_info as well. check whether it\"s necessary\n",
      "shortcut is using output[i-1] instead of x check whether works with x\n",
      "changing predictions in the nms loop make sure that it is not used later\n",
      "not adding +1 in nms\n",
      "loss: w and h aren\"t put through sqroot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving log @ /home/nvme/logs/PP/B4_0727204409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 696/3220 [02:55<11:24,  3.69it/s]"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import sleep, strftime, localtime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import tensorboardX\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from dataset import WIDERdataset, ToTensor\n",
    "from darknet import Darknet\n",
    "\n",
    "cfg_path = './cfg/yolov3_608x608_faces_only.cfg'\n",
    "model_width = 608\n",
    "batch_size = 4\n",
    "shuffle = True\n",
    "num_workers = 4\n",
    "device = torch.device('cuda:0')\n",
    "epoch_num = 50\n",
    "curr_time = strftime('%m%d%H%M%S', localtime())\n",
    "log_path = f'/home/nvme/logs/PP/{curr_time}_B{batch_size}'\n",
    "lr = 3e-4 # 3e-4 (best so far) 1e-4 (better) 3e-5 (good) 1e-5 (worse)\n",
    "\n",
    "model = Darknet(cfg_path).to(device)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "val_transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "train_dataset = WIDERdataset(\n",
    "    './data/train.json', 'train', model_width, train_transforms\n",
    ")\n",
    "val_dataset = WIDERdataset(\n",
    "    './data/val.json', 'val', model_width, val_transforms\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle, num_workers=num_workers, \n",
    "    collate_fn=train_dataset.collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size * 3, num_workers=num_workers, \n",
    "    collate_fn=val_dataset.collate_fn\n",
    ")\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr)\n",
    "\n",
    "TBoard = tensorboardX.SummaryWriter(log_dir=log_path); print(f'saving log @ {log_path}')\n",
    "# TBoard = None\n",
    "\n",
    "# todo: normalize (mean dev) the inputs\n",
    "model.train()\n",
    "\n",
    "best_metric = np.inf\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    ## TRAIN\n",
    "    model.train()\n",
    "    train_total_loss = 0\n",
    "    \n",
    "    for i, (images, targets) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        _, loss = model(images, targets[:, :6], device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_total_loss += loss.item()\n",
    "        \n",
    "        # logging\n",
    "        step_num = epoch * len(train_loader) + i\n",
    "        TBoard.add_scalar('train/loss_iter', loss.item() / len(images), step_num)\n",
    "    \n",
    "    train_total_loss /= len(train_loader)\n",
    "    TBoard.add_scalar('train/loss_epoch', train_total_loss, epoch)\n",
    "    \n",
    "        \n",
    "    ## VALIDATION\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    \n",
    "    for i, (images, targets) in enumerate(tqdm(val_loader)):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prediction, loss = model(images, targets[:, :6], device)\n",
    "            val_total_loss += loss.item()\n",
    "        \n",
    "    # logging\n",
    "    val_total_loss /= len(val_loader)\n",
    "    TBoard.add_scalar('val/loss', val_total_loss, epoch) # 472\n",
    "    \n",
    "    if val_total_loss < best_metric:\n",
    "        best_metric = val_total_loss\n",
    "        model.save_model(log_path, epoch, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

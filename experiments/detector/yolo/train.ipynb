{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset import read_wider_meta\n",
    "\n",
    "from utils import letterbox_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and write meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './data/'\n",
    "\n",
    "# calculate\n",
    "# train_meta = read_wider_meta(data_root, phase='train')\n",
    "# val_meta = read_wider_meta(data_root, phase='val')\n",
    "# test_meta = read_wider_meta(data_root, phase='test')\n",
    "\n",
    "# write\n",
    "# with open('./data/train.json', 'w') as fwrite:\n",
    "#     json.dump(train_meta, fwrite)\n",
    "    \n",
    "# with open('./data/val.json', 'w') as fwrite:\n",
    "#     json.dump(val_meta, fwrite)\n",
    "\n",
    "# with open('./data/test.json', 'w') as fwrite:\n",
    "#     json.dump(test_meta, fwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.json', 'r') as fread:\n",
    "    train_meta = json.load(fread)\n",
    "    \n",
    "with open('./data/val.json', 'r') as fread:\n",
    "    val_meta = json.load(fread)\n",
    "    \n",
    "with open('./data/test.json', 'r') as fread:\n",
    "    test_meta = json.load(fread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.transorfms\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import Compose\n",
    "from dataset import WIDERdataset, ToTensor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = WIDERdataset('./data/train.json', 'train', 608, train_transforms)\n",
    "img, targets = train_dataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'cfg_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed91fb300933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdarknet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m train_transforms = Compose([\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'cfg_path'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from dataset import WIDERdataset, ToTensor\n",
    "from darknet import Darknet\n",
    "\n",
    "cfg_path = './cfg/yolov3_608x608.cfg'\n",
    "model_width = 608\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "num_workers = 1\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = Darknet(cfg_path)\n",
    "\n",
    "train_transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "train_dataset = WIDERdataset(\n",
    "    './data/train.json', 'train', model_width, train_transforms\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size, shuffle, \n",
    "    num_workers=num_workers, collate_fn=train_dataset.collate_wider\n",
    ")\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i, (images, targets) in enumerate(tqdm(train_loader)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    _, loss = model(images, targets, device)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    print(loss / batch_size)\n",
    "    \n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

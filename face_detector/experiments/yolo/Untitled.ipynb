{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check the model cfg: augmentations, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import parse_cfg, iou_vectorized\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sudivisions of a batch aren't used in contrast to the original cfg\n",
      "we also can remove bias due to bn\n",
      "make_layers returns net_info as well. check whether it\"s necessary\n",
      "shortcut is using output[i-1] instead of x check whether works with x\n",
      "NOTE THAT CONV BEFORE YOLO USES (num_classes filters) * num_anch\n",
      "changing predictions in the nms loop make sure that it is not used later\n",
      "not adding +1 in nms\n"
     ]
    }
   ],
   "source": [
    "darknet = Darknet('cfg/yolov3_test_todel.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = 'weights/yolov3.weights'\n",
    "darknet.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(452, 602, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 416, 416])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[100.0774, 378.8565,  16.0677,  29.6695,   0.5525,   0.8951,  58.0000],\n",
       "        [283.5150, 112.5433, 103.1037, 218.4937,   1.0000,   0.9941,  16.0000],\n",
       "        [227.8112, 152.9433, 124.7233, 234.4098,   0.6576,   0.9671,  16.0000],\n",
       "        [216.5894, 169.8118, 241.9540, 201.7436,   0.9944,   0.9987,   1.0000],\n",
       "        [138.1751,  98.3323,  59.4538,  46.9861,   0.8167,   0.9892,   1.0000],\n",
       "        [121.8502, 110.1867,  59.8466,  43.6617,   0.7452,   0.9883,   1.0000],\n",
       "        [ 92.1101, 316.0642, 109.4271,  48.6384,   1.0000,   0.8345,   7.0000],\n",
       "        [ 66.8319, 347.8462, 110.6174,  56.3349,   0.9997,   0.7319,   7.0000],\n",
       "        [123.9189, 289.6150, 109.5699,  56.0721,   0.9931,   0.7168,   7.0000]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "plt.figure()\n",
    "img = cv2.imread('dog-cycle-car.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (416, 416)) / 255\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = img.transpose((2, 0, 1))\n",
    "img = torch.from_numpy(img).float()\n",
    "img = img.unsqueeze(0)\n",
    "print(img.shape)\n",
    "pred = darknet.forward(img, 'cpu')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.1483, 378.8937,  17.0948,  32.8473,   0.5465,   0.8928,  58.0000],\n",
       "        [283.4834, 112.6535, 103.2805, 223.5198,   1.0000,   0.9943,  16.0000],\n",
       "        [227.7840, 153.0189, 124.9373, 239.8021,   0.6575,   0.9681,  16.0000],\n",
       "        [216.5429, 169.9060, 242.3690, 206.3844,   0.9944,   0.9987,   1.0000],\n",
       "        [138.0303,  98.3391,  57.1368,  48.1702,   0.8130,   0.9888,   1.0000],\n",
       "        [121.7023, 110.1922,  57.5143,  44.7621,   0.7405,   0.9878,   1.0000],\n",
       "        [ 91.9664, 315.8874, 110.8051,  48.2153,   1.0000,   0.8356,   7.0000],\n",
       "        [ 66.7268, 347.6610, 112.0103,  55.8449,   0.9997,   0.7335,   7.0000],\n",
       "        [123.7692, 289.5396, 110.9496,  55.5843,   0.9931,   0.7184,   7.0000]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "# todo nms\n",
    "x = torch.randn((2, 3, 416, 416))\n",
    "device = torch.device('cpu:0')\n",
    "predictions = darknet.forward(x, device)\n",
    "predictions[:, :, 4] *= 1000 # to be removed. just for testing\n",
    "predictions = pred\n",
    "objectness_thres = 0.5\n",
    "nms_thres = 0.4\n",
    "classes = 80 # darknet.layers_list[-1][0].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [0.0667],\n",
       "        [0.0909],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes1 = torch.Tensor([(6, 5, 4, 2), (3, 6, 4, 2), (8, 4, 2, 8), (11, 7, 2, 2), (8, 0, 4, 2)]).float()\n",
    "bboxes2 = bboxes1[0].unsqueeze(0)\n",
    "\n",
    "iou_vectorized(bboxes1, bboxes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-max Suppression:\n",
    "# 1. Filter out predictions with low objectness score\n",
    "# 2. \n",
    "# objectiveness filtering:\n",
    "# replace all boxes with predicted probability lower than objectness_thres \n",
    "# with zeros: calculate 0/1 mask and apply it to the prediction tensor\n",
    "# Note: '>' returns Byte but '*' needs Float unsqueezed back to 3D\n",
    "# objectness_mask = (predictions[:, :, 4] > objectness_thres).float().unsqueeze(2)\n",
    "# predictions = predictions * objectness_mask\n",
    "\n",
    "# # \n",
    "\n",
    "\n",
    "# image_pred = predictions[0]\n",
    "# image_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 400.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing predictions in the nms loop make sure that it is not used later\n",
      "torch.Size([22, 85])\n",
      "tensor([[100.2575, 378.8981,  16.0283,  29.6745,   0.5537,   0.8899,  58.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[283.3438, 112.5091, 102.9544, 212.8765,   1.0000,   0.9941,  16.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[227.6670, 152.9198, 124.5427, 228.3836,   0.6641,   0.9669,  16.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[216.3377, 169.7828, 241.6037, 196.5571,   0.9946,   0.9987,   1.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[138.1874,  98.4530,  57.0273,  47.3960,   0.8196,   0.9886,   1.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[121.8628, 110.2799,  57.4041,  44.0426,   0.7489,   0.9876,   1.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[240.0890, 207.0442, 364.6438, 333.7238,   0.5685,   0.8301,   1.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[ 92.0773, 315.9416, 114.3170,  49.7113,   0.9999,   0.8397,   7.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[ 66.8074, 347.7177, 115.5604,  57.5776,   0.9996,   0.7394,   7.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[123.8848, 289.5620, 114.4661,  57.3089,   0.9928,   0.7245,   7.0000]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('changing predictions in the nms loop make sure that it is not used later')\n",
    "print('not adding +1')\n",
    "\n",
    "detections = [None] * len(predictions)\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "#     print(prediction.shape)\n",
    "    objectness_mask = (prediction[:, 4] > objectness_thres)#.float().unsqueeze(1)\n",
    "    prediction = prediction[objectness_mask]\n",
    "    \n",
    "    # if no object on an image found, continue with the next image\n",
    "    if prediction.size(0) == 0:\n",
    "        continue\n",
    "        \n",
    "    print(prediction.shape)\n",
    "    pred_score, pred_classes = torch.max(prediction[:, 5:5+classes], dim=1, keepdim=True)\n",
    "#     print(pred_classes.shape, pred_score.shape)\n",
    "    # detections: (cx, cy, w, h, obj_score, top_class_score, top_class_idx)\n",
    "    prediction = torch.cat((prediction[:, :5], pred_score.float(), pred_classes.float()), dim=1)\n",
    "#     print(prediction.shape)\n",
    "    unique_classes = pred_classes.unique().float()\n",
    "#     print(unique_classes.shape)\n",
    "    \n",
    "    detections_after_nms = []\n",
    "    \n",
    "    for cls in tqdm(unique_classes):\n",
    "        prediction_4_cls = prediction[prediction[:, 6] == cls]\n",
    "        sort_pred_idxs = torch.sort(prediction_4_cls[:, 4], descending=True)[1]\n",
    "        prediction_4_cls = prediction_4_cls[sort_pred_idxs]          \n",
    "        \n",
    "        while len(prediction_4_cls) > 0:\n",
    "            detections_after_nms.append(prediction_4_cls[0].unsqueeze(0))\n",
    "            print(prediction_4_cls[0].unsqueeze(0))\n",
    "            \n",
    "            if len(prediction_4_cls) == 1:\n",
    "                break\n",
    "            \n",
    "#             print('prediction_4_cls[0, :5].shape, prediction_4_cls[1:, :5].shape')\n",
    "#             print(prediction_4_cls[0, :5].shape, prediction_4_cls[1:, :5].shape)\n",
    "            ious = iou_vectorized(prediction_4_cls[0, :5].unsqueeze(0), prediction_4_cls[1:, :5])\n",
    "            ious = ious.reshape(-1)\n",
    "#             print(iou.shape)\n",
    "#             print('iou < nms_thres')\n",
    "#             print(iou < nms_thres)\n",
    "#             print(iou.shape)\n",
    "            prediction_4_cls = prediction_4_cls[1:][ious < nms_thres]\n",
    "            \n",
    "        # append to detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(detections_after_nms).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61949149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in darknet.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.runn.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm2d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

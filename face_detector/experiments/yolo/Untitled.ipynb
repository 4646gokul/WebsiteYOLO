{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check the model cfg: augmentations, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import parse_cfg\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sudivisions of a batch aren't used in contrast to the original cfg\n",
      "to del, this message should be printed 3ish times\n",
      "to del, this message should be printed 3ish times\n",
      "to del, this message should be printed 3ish times\n",
      "make_layers returns net_info as well. check whether it\"s necessary\n"
     ]
    }
   ],
   "source": [
    "darknet = Darknet('cfg/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convolutional'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darknet.layers_info[1]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-0.9665,  0.5351, -0.3072,  ...,  1.1621, -0.1265,  0.6186],\n",
      "          [ 0.6774,  0.2178, -0.0142,  ...,  0.3335,  0.8363,  2.2494],\n",
      "          [ 0.6761, -0.6914, -2.3339,  ...,  0.7657, -1.5950, -0.4754],\n",
      "          ...,\n",
      "          [-1.5157,  0.0293, -0.2095,  ...,  1.9457, -0.9569,  0.0657],\n",
      "          [-0.9379,  1.0446, -1.2633,  ..., -0.3359,  0.9698,  0.0881],\n",
      "          [ 0.5073, -0.1258,  0.0168,  ...,  0.1998,  0.2698, -0.4370]],\n",
      "\n",
      "         [[ 0.0967,  1.8158, -0.1086,  ...,  1.5871,  1.2152,  0.9816],\n",
      "          [ 0.0688, -0.7439,  0.3140,  ..., -0.7040, -1.7047,  1.5185],\n",
      "          [ 1.2309, -0.6477,  2.7795,  ...,  1.1287,  1.0372, -0.8416],\n",
      "          ...,\n",
      "          [-2.2436, -1.0690,  0.4535,  ..., -0.5805,  0.0470,  0.3810],\n",
      "          [-0.8969, -1.4079, -0.5210,  ..., -0.9237,  0.3257,  1.2608],\n",
      "          [ 0.4565,  1.2727,  0.8348,  ...,  1.6407,  0.1382, -2.1700]],\n",
      "\n",
      "         [[ 0.7127, -1.0983,  2.0368,  ...,  1.2454,  0.3194, -0.7733],\n",
      "          [ 0.3774,  0.0611, -0.0830,  ...,  1.4680, -0.0413,  0.6616],\n",
      "          [ 0.2466, -0.0849, -0.9606,  ..., -0.1403, -0.0610, -0.1689],\n",
      "          ...,\n",
      "          [-2.6396,  1.1663,  0.8560,  ...,  0.3589, -1.2518, -0.2240],\n",
      "          [-0.1300, -0.7821,  2.0949,  ...,  1.2820, -0.2817, -0.5455],\n",
      "          [ 0.3490, -1.4335,  1.7283,  ..., -1.1032, -0.1209,  1.4769]]],\n",
      "\n",
      "\n",
      "        [[[-0.8651,  1.0837, -0.6048,  ...,  0.9334, -0.5050, -0.9177],\n",
      "          [-0.2366,  1.0204,  1.2248,  ..., -0.5996,  0.6812, -0.4822],\n",
      "          [ 1.7503, -0.1589,  1.1785,  ..., -1.3653,  0.3186,  0.7298],\n",
      "          ...,\n",
      "          [-1.1866,  1.0654,  1.1041,  ...,  0.9369, -0.6978, -0.8333],\n",
      "          [-0.2980, -0.8494,  0.5953,  ...,  1.5552, -1.3228, -0.6982],\n",
      "          [-1.0601, -1.1500,  0.1175,  ...,  0.0713, -0.2523, -0.0801]],\n",
      "\n",
      "         [[ 1.7784,  1.5674, -0.6235,  ..., -0.0714, -0.3379, -0.7928],\n",
      "          [ 0.7282, -0.4487,  0.1806,  ...,  0.6910, -0.7180,  0.8590],\n",
      "          [-0.5178, -0.5093, -1.0907,  ...,  0.1878, -1.3284, -0.3051],\n",
      "          ...,\n",
      "          [ 0.6242,  0.6644, -0.3271,  ...,  1.7410, -0.5360, -1.8924],\n",
      "          [-2.4736, -0.2619,  1.9754,  ...,  1.2526,  0.7118, -0.1195],\n",
      "          [ 1.1698, -1.2833, -0.4566,  ..., -1.0674, -0.7549, -2.0061]],\n",
      "\n",
      "         [[ 0.1098, -0.7406,  0.6304,  ...,  2.4645, -1.1205, -0.4764],\n",
      "          [ 0.2102,  0.7274, -0.0927,  ...,  0.5703, -0.0316, -0.7120],\n",
      "          [ 0.0930,  0.6660,  0.7109,  ..., -0.0041,  0.6556, -1.4467],\n",
      "          ...,\n",
      "          [ 0.5640, -0.3220,  0.0475,  ..., -1.4592, -0.9339,  1.6706],\n",
      "          [-0.5958,  1.2978, -1.9623,  ...,  0.1014, -0.8741,  0.6087],\n",
      "          [-0.0666, -0.9307,  1.1053,  ...,  0.7563, -1.5983,  0.3247]]]])]\n",
      "[tensor([[[[-0.9665,  0.5351, -0.3072,  ...,  1.1621, -0.1265,  0.6186],\n",
      "          [ 0.6774,  0.2178, -0.0142,  ...,  0.3335,  0.8363,  2.2494],\n",
      "          [ 0.6761, -0.6914, -2.3339,  ...,  0.7657, -1.5950, -0.4754],\n",
      "          ...,\n",
      "          [-1.5157,  0.0293, -0.2095,  ...,  1.9457, -0.9569,  0.0657],\n",
      "          [-0.9379,  1.0446, -1.2633,  ..., -0.3359,  0.9698,  0.0881],\n",
      "          [ 0.5073, -0.1258,  0.0168,  ...,  0.1998,  0.2698, -0.4370]],\n",
      "\n",
      "         [[ 0.0967,  1.8158, -0.1086,  ...,  1.5871,  1.2152,  0.9816],\n",
      "          [ 0.0688, -0.7439,  0.3140,  ..., -0.7040, -1.7047,  1.5185],\n",
      "          [ 1.2309, -0.6477,  2.7795,  ...,  1.1287,  1.0372, -0.8416],\n",
      "          ...,\n",
      "          [-2.2436, -1.0690,  0.4535,  ..., -0.5805,  0.0470,  0.3810],\n",
      "          [-0.8969, -1.4079, -0.5210,  ..., -0.9237,  0.3257,  1.2608],\n",
      "          [ 0.4565,  1.2727,  0.8348,  ...,  1.6407,  0.1382, -2.1700]],\n",
      "\n",
      "         [[ 0.7127, -1.0983,  2.0368,  ...,  1.2454,  0.3194, -0.7733],\n",
      "          [ 0.3774,  0.0611, -0.0830,  ...,  1.4680, -0.0413,  0.6616],\n",
      "          [ 0.2466, -0.0849, -0.9606,  ..., -0.1403, -0.0610, -0.1689],\n",
      "          ...,\n",
      "          [-2.6396,  1.1663,  0.8560,  ...,  0.3589, -1.2518, -0.2240],\n",
      "          [-0.1300, -0.7821,  2.0949,  ...,  1.2820, -0.2817, -0.5455],\n",
      "          [ 0.3490, -1.4335,  1.7283,  ..., -1.1032, -0.1209,  1.4769]]],\n",
      "\n",
      "\n",
      "        [[[-0.8651,  1.0837, -0.6048,  ...,  0.9334, -0.5050, -0.9177],\n",
      "          [-0.2366,  1.0204,  1.2248,  ..., -0.5996,  0.6812, -0.4822],\n",
      "          [ 1.7503, -0.1589,  1.1785,  ..., -1.3653,  0.3186,  0.7298],\n",
      "          ...,\n",
      "          [-1.1866,  1.0654,  1.1041,  ...,  0.9369, -0.6978, -0.8333],\n",
      "          [-0.2980, -0.8494,  0.5953,  ...,  1.5552, -1.3228, -0.6982],\n",
      "          [-1.0601, -1.1500,  0.1175,  ...,  0.0713, -0.2523, -0.0801]],\n",
      "\n",
      "         [[ 1.7784,  1.5674, -0.6235,  ..., -0.0714, -0.3379, -0.7928],\n",
      "          [ 0.7282, -0.4487,  0.1806,  ...,  0.6910, -0.7180,  0.8590],\n",
      "          [-0.5178, -0.5093, -1.0907,  ...,  0.1878, -1.3284, -0.3051],\n",
      "          ...,\n",
      "          [ 0.6242,  0.6644, -0.3271,  ...,  1.7410, -0.5360, -1.8924],\n",
      "          [-2.4736, -0.2619,  1.9754,  ...,  1.2526,  0.7118, -0.1195],\n",
      "          [ 1.1698, -1.2833, -0.4566,  ..., -1.0674, -0.7549, -2.0061]],\n",
      "\n",
      "         [[ 0.1098, -0.7406,  0.6304,  ...,  2.4645, -1.1205, -0.4764],\n",
      "          [ 0.2102,  0.7274, -0.0927,  ...,  0.5703, -0.0316, -0.7120],\n",
      "          [ 0.0930,  0.6660,  0.7109,  ..., -0.0041,  0.6556, -1.4467],\n",
      "          ...,\n",
      "          [ 0.5640, -0.3220,  0.0475,  ..., -1.4592, -0.9339,  1.6706],\n",
      "          [-0.5958,  1.2978, -1.9623,  ...,  0.1014, -0.8741,  0.6087],\n",
      "          [-0.0666, -0.9307,  1.1053,  ...,  0.7563, -1.5983,  0.3247]]]])]\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "x = torch.randn((2, 3, 608, 608))\n",
    "t.append(x)\n",
    "print(t)\n",
    "x = x + 1\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-9ad423323e74>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-9ad423323e74>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    elif name = 'route':\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# todo forward use both info and modules \n",
    "x = torch.randn((2, 3, 608, 608))\n",
    "\n",
    "self_layer_list = darknet.layers_list\n",
    "self_layer_info = darknet.layers_info[1:]\n",
    "\n",
    "# cache the outputs for route and shortcut layers\n",
    "outputs = []\n",
    "\n",
    "for i, layer in enumerate(self_layer_list):\n",
    "    \n",
    "    name = self_layer_info[i]['name']\n",
    "    # TODO: append something after each layer!!!!\n",
    "    if name in ['convolutional', 'upsample']:\n",
    "        x = layer(x)\n",
    "        outputs.append(x)\n",
    "        \n",
    "    elif name == 'shortcut':\n",
    "        # index which is used for shortcut (usually '-3')\n",
    "        x = outputs[-1] + outputs[layer.frm]\n",
    "#         x = x + outputs[layer.frm]\n",
    "        outputs.append(None)\n",
    "        \n",
    "    elif name == 'route':\n",
    "        to_cat = [outputs[route_idx] for route_idx in layer.routes]\n",
    "        x = torch.cat(to_cat, dim=1)\n",
    "        outputs.append(None)\n",
    "        \n",
    "    elif name == 'yolo':\n",
    "        # input size: (B, (4+1+classes) * num_achors=255, Gi, Gi)\n",
    "        B, C, h, w = x.size()\n",
    "        # read layer's info\n",
    "        anchors = layer.anchors\n",
    "        classes = layer.classes\n",
    "        in_width = layer.in_width\n",
    "        num_anchs = len(anchors)\n",
    "        # bbox coords + obj score + class scores\n",
    "        num_feats = 4 + 1 + classes\n",
    "        \n",
    "        x = x.view(B, num_anchs, num_feats, h, w)\n",
    "        x = x.permute(0, 3, 4, 1, 2).contiguous() # (B, h, w, num_anchs, num_feats)\n",
    "        x = x.view(1, h*w*num_anchs, num_feats)\n",
    "        \n",
    "        try:\n",
    "            pass\n",
    "        \n",
    "        except NameError:\n",
    "            pass\n",
    "        \n",
    "        # output size: (B, \\sum_i{Gi*Gi*num_anchors}, (4+1+classes))\n",
    "        # todo append two times output and detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leaky_0): LeakyReLU(negative_slope=0.1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_layer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,   26,   51,   76,  101,  126,  151,  176,  201,  226,  251,  276,\n",
      "          301,  326,  351,  376,  401,  426,  451,  476,  501,  526,  551,  576,\n",
      "          601,  626,  651,  676,  701,  726,  751,  776,  801,  826,  851,  876,\n",
      "          901,  926,  951,  976, 1001, 1026, 1051, 1076, 1101, 1126, 1151, 1176,\n",
      "         1201, 1226, 1251, 1276, 1301, 1326, 1351, 1376, 1401, 1426, 1451, 1476,\n",
      "         1501, 1526, 1551, 1576, 1601, 1626, 1651, 1676, 1701, 1726, 1751, 1776,\n",
      "         1801, 1826, 1851, 1876, 1901, 1926, 1951, 1976, 2001, 2026, 2051, 2076,\n",
      "         2101, 2126, 2151, 2176, 2201, 2226, 2251, 2276, 2301, 2326, 2351, 2376,\n",
      "         2401, 2426, 2451, 2476, 2501, 2526, 2551, 2576, 2601, 2626, 2651, 2676,\n",
      "         2701, 2726, 2751, 2776, 2801, 2826, 2851, 2876, 2901, 2926, 2951, 2976,\n",
      "         3001, 3026, 3051, 3076, 3101, 3126, 3151, 3176, 3201, 3226, 3251, 3276,\n",
      "         3301, 3326, 3351, 3376, 3401, 3426, 3451, 3476, 3501, 3526, 3551, 3576,\n",
      "         3601, 3626, 3651, 3676, 3701, 3726, 3751, 3776, 3801, 3826, 3851, 3876,\n",
      "         3901, 3926, 3951, 3976, 4001, 4026, 4051, 4076, 4101, 4126, 4151, 4176,\n",
      "         4201, 4226, 4251, 4276, 4301, 4326, 4351, 4376, 4401, 4426, 4451, 4476,\n",
      "         4501, 4526, 4551, 4576, 4601, 4626, 4651, 4676, 4701, 4726, 4751, 4776,\n",
      "         4801, 4826, 4851, 4876, 4901, 4926, 4951, 4976, 5001, 5026, 5051, 5076,\n",
      "         5101, 5126, 5151, 5176, 5201, 5226, 5251, 5276, 5301, 5326, 5351, 5376,\n",
      "         5401, 5426, 5451, 5476, 5501, 5526, 5551, 5576, 5601, 5626, 5651, 5676,\n",
      "         5701, 5726, 5751, 5776, 5801, 5826, 5851, 5876, 5901, 5926, 5951, 5976,\n",
      "         6001, 6026, 6051, 6076, 6101, 6126, 6151, 6176, 6201, 6226, 6251, 6276,\n",
      "         6301, 6326, 6351]])\n",
      "tensor([[4251, 4276, 4301, 4326, 4351, 4376, 4401, 4426, 4451, 4476, 4501, 4526,\n",
      "         4551, 4576, 4601, 4626, 4651, 4676, 4701, 4726, 4751, 4776, 4801, 4826,\n",
      "         4851, 4876, 4901, 4926, 4951, 4976, 5001, 5026, 5051, 5076, 5101, 5126,\n",
      "         5151, 5176, 5201, 5226, 5251, 5276, 5301, 5326, 5351, 5376, 5401, 5426,\n",
      "         5451, 5476, 5501, 5526, 5551, 5576, 5601, 5626, 5651, 5676, 5701, 5726,\n",
      "         5751, 5776, 5801, 5826, 5851, 5876, 5901, 5926, 5951, 5976, 6001, 6026,\n",
      "         6051, 6076, 6101, 6126, 6151, 6176, 6201, 6226, 6251, 6276, 6301, 6326,\n",
      "         6351]])\n"
     ]
    }
   ],
   "source": [
    "# TODO proper transformation\n",
    "a = torch.arange(1*(80+5)*3*5*5).view(1, 255, 5, 5)\n",
    "# print(a)\n",
    "print(a[:, :, 0, 1])\n",
    "a = a.view(1, 3, 85, 5, 5).permute(0, 3, 4, 1, 2).contiguous().view(1, 75, 85)\n",
    "print(a[:, 5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

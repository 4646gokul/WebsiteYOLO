{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check the model cfg: augmentations, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils import parse_cfg\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sudivisions of a batch aren't used in contrast to the original cfg\n",
      "to del, this message should be printed 3ish times\n",
      "to del, this message should be printed 3ish times\n",
      "to del, this message should be printed 3ish times\n",
      "make_layers returns net_info as well. check whether it\"s necessary\n",
      "shortcut is using output[i-1] instead of x check whether works with x\n",
      "NOTE THAT CONV BEFORE YOLO USES (num_classes filters) * num_anch\n"
     ]
    }
   ],
   "source": [
    "darknet = Darknet('cfg/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 32,\n",
       " 64,\n",
       " 32,\n",
       " 64,\n",
       " 128,\n",
       " 64,\n",
       " 128,\n",
       " 64,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 512,\n",
       " 1024,\n",
       " 255,\n",
       " 1024,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 256,\n",
       " 512,\n",
       " 255,\n",
       " 512,\n",
       " 128,\n",
       " 384,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 128,\n",
       " 256,\n",
       " 255]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darknet.filters_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9272, 0.8688, 0.7273,  ..., 0.9769, 0.3683, 0.3115],\n",
      "         [0.2115, 0.6499, 0.5213,  ..., 0.9838, 0.2816, 0.5502],\n",
      "         [0.0281, 0.3653, 0.7759,  ..., 0.1455, 0.4885, 0.3471],\n",
      "         ...,\n",
      "         [0.4669, 0.1822, 0.6258,  ..., 0.0174, 0.5350, 0.4395],\n",
      "         [0.6263, 0.0082, 0.5887,  ..., 0.4463, 0.3623, 0.6832],\n",
      "         [0.8101, 0.8784, 0.3168,  ..., 0.1351, 0.2711, 0.4058]]])\n",
      "tensor([[[0.9272, 0.8688, 0.7273,  ..., 0.9769, 0.3683, 0.3115],\n",
      "         [0.2115, 0.6499, 0.5213,  ..., 0.9838, 0.2816, 0.5502],\n",
      "         [0.0281, 0.3653, 0.7759,  ..., 0.1455, 0.4885, 0.3471],\n",
      "         ...,\n",
      "         [0.4669, 0.1822, 0.6258,  ..., 0.0174, 0.5350, 0.4395],\n",
      "         [0.6263, 0.0082, 0.5887,  ..., 0.4463, 0.3623, 0.6832],\n",
      "         [0.8101, 0.8784, 0.3168,  ..., 0.1351, 0.2711, 0.4058]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 13, 85)\n",
    "\n",
    "try:\n",
    "    predictions = torch.cat((predictions, x), dim=1)\n",
    "        \n",
    "except NameError:\n",
    "    predictions = x\n",
    "    \n",
    "print(predictions)\n",
    "l = torch.nn.Conv1d(13, 2, 3)\n",
    "x = l(x)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 convolutional\n",
      "torch.Size([2, 3, 608, 608]) Sequential(\n",
      "  (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_0): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "1 convolutional\n",
      "torch.Size([2, 32, 608, 608]) Sequential(\n",
      "  (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_1): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "2 convolutional\n",
      "torch.Size([2, 64, 304, 304]) Sequential(\n",
      "  (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_2): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "3 convolutional\n",
      "torch.Size([2, 32, 304, 304]) Sequential(\n",
      "  (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_3): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "4 shortcut\n",
      "5 convolutional\n",
      "torch.Size([2, 64, 304, 304]) Sequential(\n",
      "  (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_5): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "6 convolutional\n",
      "torch.Size([2, 128, 152, 152]) Sequential(\n",
      "  (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_6): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "7 convolutional\n",
      "torch.Size([2, 64, 152, 152]) Sequential(\n",
      "  (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_7): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "8 shortcut\n",
      "9 convolutional\n",
      "torch.Size([2, 128, 152, 152]) Sequential(\n",
      "  (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_9): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "10 convolutional\n",
      "torch.Size([2, 64, 152, 152]) Sequential(\n",
      "  (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_10): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "11 shortcut\n",
      "12 convolutional\n",
      "torch.Size([2, 128, 152, 152]) Sequential(\n",
      "  (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_12): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "13 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_13): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "14 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_14): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "15 shortcut\n",
      "16 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_16): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "17 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_17): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "18 shortcut\n",
      "19 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_19): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "20 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_20): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "21 shortcut\n",
      "22 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_22): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "23 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_23): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "24 shortcut\n",
      "25 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_25): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "26 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_26): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "27 shortcut\n",
      "28 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_28): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "29 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_29): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "30 shortcut\n",
      "31 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_31): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "32 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_32): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "33 shortcut\n",
      "34 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_34): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "35 convolutional\n",
      "torch.Size([2, 128, 76, 76]) Sequential(\n",
      "  (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_35): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "36 shortcut\n",
      "37 convolutional\n",
      "torch.Size([2, 256, 76, 76]) Sequential(\n",
      "  (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_37): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "38 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_38): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "39 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_39): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "40 shortcut\n",
      "41 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_41): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "42 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_42): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "43 shortcut\n",
      "44 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_44): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "45 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_45): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "46 shortcut\n",
      "47 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_47): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "48 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_48): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "49 shortcut\n",
      "50 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_50): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "51 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_51): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "52 shortcut\n",
      "53 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_53): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "54 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_54): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "55 shortcut\n",
      "56 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_56): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "57 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_57): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "58 shortcut\n",
      "59 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_59): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "60 convolutional\n",
      "torch.Size([2, 256, 38, 38]) Sequential(\n",
      "  (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_60): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "61 shortcut\n",
      "62 convolutional\n",
      "torch.Size([2, 512, 38, 38]) Sequential(\n",
      "  (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (bn_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_62): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "63 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_63): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "64 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_64): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "65 shortcut\n",
      "66 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_66): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "67 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_67): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "68 shortcut\n",
      "69 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_69): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "70 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_70): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "71 shortcut\n",
      "72 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_72): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "73 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_73): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "74 shortcut\n",
      "75 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_75): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "76 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_76): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "77 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_77): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "78 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_78): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "79 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_79): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "80 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_80): LeakyReLU(negative_slope=0.1)\n",
      ")\n",
      "81 convolutional\n",
      "torch.Size([2, 1024, 19, 19]) Sequential(\n",
      "  (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "82 yolo\n",
      "torch.Size([2, 255, 19, 19])\n",
      "83 route\n",
      "84 convolutional\n",
      "torch.Size([2, 512, 19, 19]) Sequential(\n",
      "  (conv_84): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (bn_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (leaky_84): LeakyReLU(negative_slope=0.1)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 1024, 1, 1], expected input[2, 512, 19, 19] to have 1024 channels, but got 512 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2d0604381a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'convolutional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'upsample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'shortcut'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/main/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 1024, 1, 1], expected input[2, 512, 19, 19] to have 1024 channels, but got 512 channels instead"
     ]
    }
   ],
   "source": [
    "# todo forward use both info and modules \n",
    "x = torch.randn((2, 3, 608, 608))\n",
    "device = 'cpu'\n",
    "\n",
    "self_layer_list = darknet.layers_list\n",
    "self_layer_info = darknet.layers_info[1:]\n",
    "\n",
    "# cache the outputs for route and shortcut layers\n",
    "outputs = []\n",
    "\n",
    "for i, layer in enumerate(self_layer_list):\n",
    "    name = self_layer_info[i]['name']\n",
    "    print(i, name)\n",
    "    # TODO: append something after each layer!!!!\n",
    "    if name in ['convolutional', 'upsample']:\n",
    "        print(x.shape, layer)\n",
    "        x = layer(x)\n",
    "        \n",
    "    elif name == 'shortcut':\n",
    "        # index which is used for shortcut (usually '-3')\n",
    "        x = outputs[-1] + outputs[layer[0].frm]\n",
    "#         x = x + outputs[layer.frm]\n",
    "        \n",
    "    elif name == 'route':\n",
    "        to_cat = [outputs[route_idx] for route_idx in layer[0].routes]\n",
    "        x = torch.cat(to_cat, dim=1)\n",
    "        \n",
    "    elif name == 'yolo':\n",
    "        # input size: (B, (4+1+classes)*num_achors=255, Gi, Gi)\n",
    "        print(x.shape)\n",
    "        B, C, w, h = x.size()\n",
    "        # read layer's info\n",
    "        anchors_list = layer[0].anchors\n",
    "        classes = layer[0].classes\n",
    "        in_width = layer[0].in_width\n",
    "        num_anchs = len(anchors_list)\n",
    "        # bbox coords + obj score + class scores\n",
    "        num_feats = 4 + 1 + classes\n",
    "        \n",
    "        # transform the predictions\n",
    "        # (B, ((4+1+classes)*num_achors), Gi, Gi)\n",
    "        # -> (B, Gi*Gi*num_anchors, (4+1+classes))\n",
    "        x = x.view(B, num_anchs, num_feats, w, h)\n",
    "        x = x.permute(0, 3, 4, 1, 2).contiguous() # (B, w, h, num_anchs, num_feats)\n",
    "        x = x.view(B, h*w*num_anchs, num_feats)\n",
    "        \n",
    "        # To calc predictions, first we need to add a center offset (cx, cy).\n",
    "        # To achieve this we need to create two columns with every possible \n",
    "        # combination of two numbers from 0 to num_grid and\n",
    "        # then add it to the center offset predictions at 0 and 1 indices\n",
    "        # in x.\n",
    "        grid = torch.arange(w)\n",
    "        a, b = torch.meshgrid(grid, grid)\n",
    "        cx = a.type(torch.FloatTensor).view(-1, 1) # 0, 0, ..., 12, 12\n",
    "        cy = b.type(torch.FloatTensor).view(-1, 1) # 0, 1, ..., 11, 12\n",
    "        # cxy.shape is (1, *, 2) where (:, :, 0) is an offset for cx, (:, :, 1) -- for cy\n",
    "        cxy = torch.cat((cx, cy), dim=1).repeat(1, num_anchs).view(-1, 2).unsqueeze(0)\n",
    "        cxy = cxy.to(device)\n",
    "        \n",
    "        # to calc the offsets for bbox size we need to scale anchors\n",
    "        stride = in_width // w\n",
    "        anchors_list = [(anchor[0] / stride, anchor[1] / stride) for anchor in anchors_list]\n",
    "        anchors_tens = torch.FloatTensor(anchors_list)\n",
    "        # pwh.shape is the same as cxy\n",
    "        pwh = anchors_tens.repeat(w * w, 1).unsqueeze(0)\n",
    "        pwh = pwh.to(device)\n",
    "        \n",
    "        # transform the predictions\n",
    "        x[:, :, 0:2] = torch.sigmoid(x[:, :, 0:2]) + cxy\n",
    "        x[:, :, 2:4] = pwh * torch.exp(x[:, :, 2:4])\n",
    "        x[:, :, 4] = torch.sigmoid(x[:, :, 4]) * stride\n",
    "        x[:, :, 5:5+classes] = torch.sigmoid((x[:, :, 5:5+classes]))\n",
    "        \n",
    "        # add new predictions to the list of predictions from all scales\n",
    "        try:\n",
    "#             print(x.shape, predictions.shape)\n",
    "            predictions = torch.cat((predictions, x), dim=1)\n",
    "\n",
    "        except NameError:\n",
    "            predictions = x\n",
    "            \n",
    "    outputs.append(x)\n",
    "        \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_layer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,   26,   51,   76,  101,  126,  151,  176,  201,  226,  251,  276,\n",
      "          301,  326,  351,  376,  401,  426,  451,  476,  501,  526,  551,  576,\n",
      "          601,  626,  651,  676,  701,  726,  751,  776,  801,  826,  851,  876,\n",
      "          901,  926,  951,  976, 1001, 1026, 1051, 1076, 1101, 1126, 1151, 1176,\n",
      "         1201, 1226, 1251, 1276, 1301, 1326, 1351, 1376, 1401, 1426, 1451, 1476,\n",
      "         1501, 1526, 1551, 1576, 1601, 1626, 1651, 1676, 1701, 1726, 1751, 1776,\n",
      "         1801, 1826, 1851, 1876, 1901, 1926, 1951, 1976, 2001, 2026, 2051, 2076,\n",
      "         2101, 2126, 2151, 2176, 2201, 2226, 2251, 2276, 2301, 2326, 2351, 2376,\n",
      "         2401, 2426, 2451, 2476, 2501, 2526, 2551, 2576, 2601, 2626, 2651, 2676,\n",
      "         2701, 2726, 2751, 2776, 2801, 2826, 2851, 2876, 2901, 2926, 2951, 2976,\n",
      "         3001, 3026, 3051, 3076, 3101, 3126, 3151, 3176, 3201, 3226, 3251, 3276,\n",
      "         3301, 3326, 3351, 3376, 3401, 3426, 3451, 3476, 3501, 3526, 3551, 3576,\n",
      "         3601, 3626, 3651, 3676, 3701, 3726, 3751, 3776, 3801, 3826, 3851, 3876,\n",
      "         3901, 3926, 3951, 3976, 4001, 4026, 4051, 4076, 4101, 4126, 4151, 4176,\n",
      "         4201, 4226, 4251, 4276, 4301, 4326, 4351, 4376, 4401, 4426, 4451, 4476,\n",
      "         4501, 4526, 4551, 4576, 4601, 4626, 4651, 4676, 4701, 4726, 4751, 4776,\n",
      "         4801, 4826, 4851, 4876, 4901, 4926, 4951, 4976, 5001, 5026, 5051, 5076,\n",
      "         5101, 5126, 5151, 5176, 5201, 5226, 5251, 5276, 5301, 5326, 5351, 5376,\n",
      "         5401, 5426, 5451, 5476, 5501, 5526, 5551, 5576, 5601, 5626, 5651, 5676,\n",
      "         5701, 5726, 5751, 5776, 5801, 5826, 5851, 5876, 5901, 5926, 5951, 5976,\n",
      "         6001, 6026, 6051, 6076, 6101, 6126, 6151, 6176, 6201, 6226, 6251, 6276,\n",
      "         6301, 6326, 6351]])\n",
      "tensor([[4251, 4276, 4301, 4326, 4351, 4376, 4401, 4426, 4451, 4476, 4501, 4526,\n",
      "         4551, 4576, 4601, 4626, 4651, 4676, 4701, 4726, 4751, 4776, 4801, 4826,\n",
      "         4851, 4876, 4901, 4926, 4951, 4976, 5001, 5026, 5051, 5076, 5101, 5126,\n",
      "         5151, 5176, 5201, 5226, 5251, 5276, 5301, 5326, 5351, 5376, 5401, 5426,\n",
      "         5451, 5476, 5501, 5526, 5551, 5576, 5601, 5626, 5651, 5676, 5701, 5726,\n",
      "         5751, 5776, 5801, 5826, 5851, 5876, 5901, 5926, 5951, 5976, 6001, 6026,\n",
      "         6051, 6076, 6101, 6126, 6151, 6176, 6201, 6226, 6251, 6276, 6301, 6326,\n",
      "         6351]])\n"
     ]
    }
   ],
   "source": [
    "# TODO proper transformation\n",
    "a = torch.arange(1*(80+5)*3*5*5).view(1, 255, 5, 5)\n",
    "# print(a)\n",
    "print(a[:, :, 0, 1])\n",
    "a = a.view(1, 3, 85, 5, 5).permute(0, 3, 4, 1, 2).contiguous().view(1, 75, 85)\n",
    "print(a[:, 5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

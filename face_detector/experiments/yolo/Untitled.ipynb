{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check the model cfg: augmentations, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from utils import parse_cfg\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_info = parse_cfg('cfg/yolov3.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sudivisions of a batch aren't used in contrast to the original cfg\n",
      "make_layers returns net_info as well. check whether it\"s necessary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'angle': '0',\n",
       "  'batch': '64',\n",
       "  'burn_in': '1000',\n",
       "  'channels': '3',\n",
       "  'decay': '0.0005',\n",
       "  'exposure': '1.5',\n",
       "  'height': '608',\n",
       "  'hue': '.1',\n",
       "  'learning_rate': '0.001',\n",
       "  'max_batches': '500200',\n",
       "  'momentum': '0.9',\n",
       "  'name': 'net',\n",
       "  'policy': 'steps',\n",
       "  'saturation': '1.5',\n",
       "  'scales': '.1,.1',\n",
       "  'steps': '400000,450000',\n",
       "  'subdivisions': '16',\n",
       "  'width': '608'},\n",
       " ModuleList(\n",
       "   (0): Sequential(\n",
       "     (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (bn_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (leaky_0): LeakyReLU(negative_slope=0.1)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darknet = Darknet(layers_info)\n",
    "darknet.create_layers() #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-18-58f685282415>, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-58f685282415>\"\u001b[0;36m, line \u001b[0;32m69\u001b[0m\n\u001b[0;31m    layer_list.append(layer)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# the first element is not a layer but the network info (lr, batchsize,  ...)\n",
    "net_info = layers_info[0]\n",
    "# init. the modulelist instead of a list to add all parameters to nn.Module\n",
    "layer_list = nn.ModuleList()\n",
    "\n",
    "print(\"WARNING: sudivisions of a batch aren't used in contrast to the original cfg\" )\n",
    "\n",
    "for i, layer_info in layers_info[1:]:\n",
    "    # we initialize sequential as a layer may have conv, bn, and activation\n",
    "    layer = nn.Sequential()\n",
    "    # cache the # of filters as we will need them in Conv2d\n",
    "    # it starts with the number of channels specified in net info, often = to 3 (RGB)\n",
    "    filters_cache = [int(net_info['channels'])]\n",
    "    name = layer_info['name'] # conv, upsample, route, shortcut, yolo\n",
    "    \n",
    "    if name == 'convolutional':\n",
    "        # extract arguments for the layer\n",
    "        in_filters = filters_cache[-1]\n",
    "        out_filters = int(layer_info['filters'])\n",
    "        kernel_size = int(layer_info['size'])\n",
    "        pad = (kernel_size - 1) // 2 if int(module_def['pad']) else 0\n",
    "        stride = int(layer_info['stride'])\n",
    "        \n",
    "        # make conv module and add it to the sequential\n",
    "        conv = nn.Conv2d(in_filters, out_filters, kernel_size, stride, pad)\n",
    "        layer.add_module('conv_{}'.format(i), conv)\n",
    "        \n",
    "        # some layers doesn't have BN\n",
    "        try:\n",
    "            layer_info['batch_normalize']\n",
    "            layer.add_module('bn_' + i, nn.BatchNorm2d(out_filters))\n",
    "            \n",
    "        except KeyError:\n",
    "            print('to del, this message should be printed 3ish times')\n",
    "            pass\n",
    "        \n",
    "        # activation. if 'linear': no activation\n",
    "        if layer_info['activation'] == 'leaky':\n",
    "            layer.add_module('leaky_' + i, nn.LeakyReLU(0.1))\n",
    "        \n",
    "        # add the number of filters to filters_cache\n",
    "        filters_cache.append(out_filters)\n",
    "    \n",
    "    elif name == 'upsample':\n",
    "        # extract arguments for the layer\n",
    "        stride = int(layer_info['stride'])\n",
    "        layer.add_module('upsample_' + i, nn.Upsample(scale_factor=stride, mode='bilinear'))\n",
    "        \n",
    "    # here we need to deal only with the number of filters \n",
    "    elif name == 'route':\n",
    "        # route can have one, two, or more sources\n",
    "        # first, let's make them to be ints\n",
    "        routes = [int(route) for route in layer_info['layers'].split(',')]\n",
    "        # then, sum the number of filters from at each mentioned layer\n",
    "        out_filters = sum([filters_cache[route] for route in routes])\n",
    "#         # add the dummy layer to the list\n",
    "#         layer.add_module('route_' + i, EmptyLayer())\n",
    "        # add the route layer to the modulelist\n",
    "        layer.add_module('route_' + i, RouteLayer(routes))\n",
    "        \n",
    "        # add the number of filters to filters_cache\n",
    "        filters_cache.append(out_filters)\n",
    "    \n",
    "    # in forward() we will need to add the output of a previous layer, nothing to do here\n",
    "    elif name == 'shortcut':\n",
    "        # from which layer to use the shortcut\n",
    "        frm = int(layer_info['from'])\n",
    "        # add the shortcut layer to the modulelist\n",
    "        layer.add_module('shortcut_' + i, ShortcutLayer(frm))\n",
    "        \n",
    "    # detection layer\n",
    "    elif name == 'yolo':\n",
    "        # extract arguments for the layer\n",
    "        classes = int(layer_info['classes'])\n",
    "        num = int(layer_info['num'])\n",
    "        jitter = float(layer_info['jitter'])\n",
    "        ignore_thresh = float(layer_info['ignore_thresh'])\n",
    "        truth_thresh = float(layer_info['truth_thresh']) \n",
    "        random = float(layer_info['random']) # float??\n",
    "        in_width = int(net_info['width'])\n",
    "        \n",
    "        # masks tells the dector which anchor to use (form: '6,7,8')\n",
    "        masks = [int(mask) for mask in layer_info['mask'].split(',')]\n",
    "        # select anchors (form: 10,13,16,30,33,23,30,61,62,45 -- 5 pairs)\n",
    "        # first extract the coordinates\n",
    "        coords = [int(coord) for coord in layer_info['anchors']]\n",
    "        # make anchors (tuples)\n",
    "        anchors = list(zip(coords[::2], coords[1::2]))\n",
    "        # select anchors that belong to mask\n",
    "        anchors = [anchors[mask] for mask in masks]\n",
    "        \n",
    "        # add the detector layer to the list\n",
    "        detection = DetectionLayer(anchors, classes, num, jitter, ignore_thresh, truth_thresh, random, in_width)\n",
    "        layer.add_module('detector_' + i, detection)\n",
    "        \n",
    "    \n",
    "    # append the layer to the modulelist\n",
    "    layer_list.append(layer)\n",
    "    \n",
    "    print('make_layers returns net_info as well. check whether it\"s necessary')\n",
    "    return net_info, layer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0.0:\n",
    "    print(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(10, 13),\n",
       " (16, 30),\n",
       " (33, 23),\n",
       " (30, 61),\n",
       " (62, 45),\n",
       " (59, 119),\n",
       " (116, 90),\n",
       " (156, 198),\n",
       " (373, 326)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_info = {'anchors': '10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326'}\n",
    "coords = [int(coord) for coord in layer_info['anchors'].replace(' ', '').split(',')]\n",
    "print(coords)\n",
    "list(zip(coords[::2], coords[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '32',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '64',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '2'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear', 'from': '-3', 'name': 'shortcut'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '1024',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'anchors': '10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.7',\n",
       "  'jitter': '.3',\n",
       "  'mask': '6,7,8',\n",
       "  'name': 'yolo',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1'},\n",
       " {'layers': '-4', 'name': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'name': 'upsample', 'stride': '2'},\n",
       " {'layers': '-1,61', 'name': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '512',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'anchors': '10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.7',\n",
       "  'jitter': '.3',\n",
       "  'mask': '3,4,5',\n",
       "  'name': 'yolo',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1'},\n",
       " {'layers': '-4', 'name': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'name': 'upsample', 'stride': '2'},\n",
       " {'layers': '-1,36', 'name': 'route'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '128',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'activation': 'leaky',\n",
       "  'batch_normalize': '1',\n",
       "  'filters': '256',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '3',\n",
       "  'stride': '1'},\n",
       " {'activation': 'linear',\n",
       "  'filters': '255',\n",
       "  'name': 'convolutional',\n",
       "  'pad': '1',\n",
       "  'size': '1',\n",
       "  'stride': '1'},\n",
       " {'anchors': '10,13,16,30,33,23,30,61,62,45,59,119,116,90,156,198,373,326',\n",
       "  'classes': '80',\n",
       "  'ignore_thresh': '.7',\n",
       "  'jitter': '.3',\n",
       "  'mask': '0,1,2',\n",
       "  'name': 'yolo',\n",
       "  'num': '9',\n",
       "  'random': '1',\n",
       "  'truth_thresh': '1'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_info[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
